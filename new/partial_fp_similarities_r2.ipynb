{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqCclpcW_IEt",
        "outputId": "5fa201c5-df64-43d9-b411-0d8509f817f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Loaded sim shape (1000, 1000)\n",
            "Using N = 1000 formulas (subset).\n",
            "Observed edges: 249750 Unobserved pairs: 249750\n",
            "Train observed pairs: 224775 Holdout pairs: 24975\n",
            "FP shape: (1000, 264)\n",
            "[Epoch 1] train_edge_loss=0.065019\n",
            "[Holdout edges] MSE=0.064832 MAE=0.233688 R2=-3.900 Pearson=0.146 Spearman=0.177\n",
            "[Epoch 2] train_edge_loss=0.062936\n",
            "[Holdout edges] MSE=0.063093 MAE=0.230358 R2=-3.769 Pearson=0.142 Spearman=0.183\n",
            "[Epoch 3] train_edge_loss=0.058305\n",
            "[Holdout edges] MSE=0.058140 MAE=0.220419 R2=-3.395 Pearson=0.144 Spearman=0.181\n",
            "[Epoch 5] train_edge_loss=0.045988\n",
            "[Holdout edges] MSE=0.045856 MAE=0.191659 R2=-2.466 Pearson=0.138 Spearman=0.156\n",
            "[Epoch 10] train_edge_loss=0.031432\n",
            "[Holdout edges] MSE=0.031338 MAE=0.152474 R2=-1.369 Pearson=0.255 Spearman=0.263\n",
            "[Epoch 20] train_edge_loss=0.018238\n",
            "[Holdout edges] MSE=0.017949 MAE=0.103665 R2=-0.357 Pearson=0.336 Spearman=0.320\n",
            "[Epoch 50] train_edge_loss=0.009705\n",
            "[Holdout edges] MSE=0.009689 MAE=0.074563 R2=0.268 Pearson=0.559 Spearman=0.521\n",
            "[Epoch 100] train_edge_loss=0.007300\n",
            "[Holdout edges] MSE=0.007214 MAE=0.063595 R2=0.455 Pearson=0.697 Spearman=0.637\n",
            "[Epoch 200] train_edge_loss=0.011364\n",
            "[Holdout edges] MSE=0.011180 MAE=0.089798 R2=0.155 Pearson=0.767 Spearman=0.714\n",
            "[Final Holdout] MSE=0.004021 MAE=0.041707 R2=0.696 Pearson=0.839 Spearman=0.772\n",
            "Example predicted unobserved (first 20): [0.51565754 0.42886996 0.51421887 0.54810864 0.5461003  0.48142648\n",
            " 0.49497682 0.5283659  0.47352624 0.47989193 0.4798697  0.41391066\n",
            " 0.52379155 0.5150235  0.54301184 0.49926752 0.50507075 0.4835766\n",
            " 0.45280463 0.49396056]\n",
            "Saved artifacts to joint_edges_artifacts_semantic_fp.npz\n"
          ]
        }
      ],
      "source": [
        "# joint_edges_only_semantic_fp.py\n",
        "\"\"\"\n",
        "Graph Completion (APPNP-style) using semantic fingerprints (truth-probe mini-worlds + structural counts)\n",
        "Node label prediction removed: task is only predicting missing similarities.\n",
        "\"\"\"\n",
        "\n",
        "import os, random, math, re, hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------------- CONFIG ----------------------\n",
        "CSV_PATH           = \"/content/30_1000_base.csv\"  # <<-- set your file path\n",
        "SEED               = 7\n",
        "SUBSET_SIZE        = None       # None = full dataset\n",
        "OBS_MISSING_FRAC   = 0.5\n",
        "HOLDOUT_EDGE_FRAC  = 0.10\n",
        "EMBED_DIM          = 128\n",
        "\n",
        "# Semantic FP params\n",
        "M_PROBES           = 256\n",
        "\n",
        "# Training hyperparams\n",
        "EPOCHS             = 200\n",
        "BATCH_EDGES_SIZE   = 40000\n",
        "LR                 = 1e-3\n",
        "APPNP_K            = 10\n",
        "APPNP_ALPHA        = 0.1\n",
        "EDGE_TEMP          = 1.0\n",
        "EDGE_LOSS_W        = 1.0\n",
        "BLOCK_PRED         = 128\n",
        "DEVICE             = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "OUT_ARTIFACT       = \"joint_edges_artifacts_semantic_fp.npz\"\n",
        "\n",
        "# reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# ---------------------- Utilities ----------------------\n",
        "def load_sim_and_labels(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if df.shape[1] < 2:\n",
        "        raise ValueError(\"CSV must have at least two columns: label + similarity columns\")\n",
        "    # Labels are ignored\n",
        "    sim = df.iloc[:, 1:].to_numpy(dtype=np.float32)\n",
        "    if sim.shape[0] != sim.shape[1]:\n",
        "        raise ValueError(f\"Similarity submatrix must be square, got {sim.shape}\")\n",
        "    formulas = list(df.columns[1:])\n",
        "    return sim, formulas\n",
        "\n",
        "def sample_subset(sim, formulas, subset_size=None, seed=SEED):\n",
        "    N = sim.shape[0]\n",
        "    if subset_size is None or subset_size >= N:\n",
        "        idx = np.arange(N, dtype=np.int64)\n",
        "    else:\n",
        "        rng = np.random.RandomState(seed)\n",
        "        idx = rng.choice(N, subset_size, replace=False).astype(np.int64)\n",
        "    return sim[np.ix_(idx, idx)].copy(), [formulas[i] for i in idx.tolist()], idx\n",
        "\n",
        "def upper_pairs(N):\n",
        "    I, J = np.triu_indices(N, k=1)\n",
        "    return np.stack([I, J], axis=1)\n",
        "\n",
        "def build_obs_pairs_from_sim(sim, obs_fraction=OBS_MISSING_FRAC, seed=SEED):\n",
        "    N = sim.shape[0]\n",
        "    all_pairs = upper_pairs(N)\n",
        "    total = len(all_pairs)\n",
        "    m_obs = max(1, int(obs_fraction * total))\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sel = rng.choice(total, m_obs, replace=False)\n",
        "    obs_pairs_all = all_pairs[sel].astype(np.int64)\n",
        "    obs_vals_all = sim[obs_pairs_all[:,0], obs_pairs_all[:,1]].astype(np.float32)\n",
        "    obs_set = set(map(tuple, obs_pairs_all.tolist()))\n",
        "    unobs_pairs = np.array([p for p in all_pairs.tolist() if tuple(p) not in obs_set], dtype=np.int64)\n",
        "    return obs_pairs_all, obs_vals_all, unobs_pairs\n",
        "\n",
        "def split_holdout(obs_pairs_all, obs_vals_all, holdout_frac=HOLDOUT_EDGE_FRAC, seed=SEED):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n = len(obs_pairs_all)\n",
        "    perm = rng.permutation(n)\n",
        "    m_hold = max(1, int(holdout_frac * n))\n",
        "    hold_idx = perm[:m_hold]\n",
        "    train_idx = perm[m_hold:]\n",
        "    return obs_pairs_all[train_idx], obs_vals_all[train_idx], obs_pairs_all[hold_idx], obs_vals_all[hold_idx]\n",
        "\n",
        "def build_A_hat_from_obs(N, pairs_idx, weights, edge_temp=EDGE_TEMP, device=DEVICE):\n",
        "    pairs_idx = np.asarray(pairs_idx, dtype=np.int64)\n",
        "    weights = np.asarray(weights, dtype=np.float32)\n",
        "    w = np.clip(weights, 0.0, 1.0)\n",
        "    if edge_temp != 1.0:\n",
        "        w = np.exp(edge_temp * w)\n",
        "    rows = np.concatenate([pairs_idx[:,0], pairs_idx[:,1]])\n",
        "    cols = np.concatenate([pairs_idx[:,1], pairs_idx[:,0]])\n",
        "    vals = np.concatenate([w, w]).astype(np.float32)\n",
        "    rows = np.concatenate([rows, np.arange(N, dtype=np.int64)])\n",
        "    cols = np.concatenate([cols, np.arange(N, dtype=np.int64)])\n",
        "    vals = np.concatenate([vals, np.ones(N, dtype=np.float32)])\n",
        "    A = sp.coo_matrix((vals, (rows, cols)), shape=(N, N)).tocsr()\n",
        "    d = np.array(A.sum(1)).ravel()\n",
        "    d_inv_sqrt = 1.0 / np.sqrt(np.maximum(d, 1e-12))\n",
        "    D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    A_hat = (D_inv_sqrt @ A @ D_inv_sqrt).tocoo()\n",
        "    idx = np.vstack([A_hat.row, A_hat.col]).astype(np.int64)\n",
        "    val = A_hat.data.astype(np.float32)\n",
        "    i = torch.tensor(idx, dtype=torch.long, device=device)\n",
        "    v = torch.tensor(val, dtype=torch.float32, device=device)\n",
        "    return torch.sparse_coo_tensor(i, v, (N, N), device=device)\n",
        "\n",
        "# ---------------------- Semantic fingerprint ----------------------\n",
        "OP_MAP = {\"→\":\" IMP \",\"⇒\":\" IMP \",\"=>\":\" IMP \",\"->\":\" IMP \",\n",
        "          \"↔\":\" IFF \",\"<=>\":\" IFF \",\"<->\":\" IFF \",\n",
        "          \"⊑\":\" SUB \",\n",
        "          \"⊓\":\" AND \",\"∧\":\" AND \",\"&&\":\" AND \",\n",
        "          \"⊔\":\" OR  \",\"∨\":\" OR  \",\"||\":\" OR  \",\n",
        "          \"¬\":\" NOT \",\"~\":\" NOT \",\"!\":\" NOT \"}\n",
        "BIN_OPS, UNARY_OPS = {\"AND\",\"OR\",\"IMP\",\"IFF\",\"SUB\"}, {\"NOT\"}\n",
        "TOKEN_RE = re.compile(r\"[A-Za-z0-9_]+|[()]\")\n",
        "\n",
        "def norm_text(s):\n",
        "    s = str(s)\n",
        "    for k,v in OP_MAP.items(): s = s.replace(k,v)\n",
        "    return s\n",
        "\n",
        "def lex(s): return TOKEN_RE.findall(norm_text(s))\n",
        "def is_atom(t): return t not in BIN_OPS|UNARY_OPS|{\"(\",\")\"}\n",
        "\n",
        "class Parser:\n",
        "    def __init__(self,toks): self.toks=toks; self.i=0\n",
        "    def peek(self): return self.toks[self.i] if self.i<len(self.toks) else None\n",
        "    def pop(self): t=self.peek(); self.i += (1 if t is not None else 0); return t\n",
        "    PREC = {\"IFF\":1,\"IMP\":2,\"SUB\":2,\"OR\":3,\"AND\":4}\n",
        "    RIGHT = {\"IMP\",\"IFF\",\"SUB\"}\n",
        "    def expr(self,minp):\n",
        "        node=self.unary()\n",
        "        while True:\n",
        "            op=self.peek()\n",
        "            if op in BIN_OPS:\n",
        "                prec=self.PREC.get(op,0)\n",
        "                if prec<minp: break\n",
        "                self.pop()\n",
        "                nextp = prec if op in self.RIGHT else prec+1\n",
        "                rhs=self.expr(nextp)\n",
        "                node=(\"BIN\",op,node,rhs)\n",
        "            else: break\n",
        "        return node\n",
        "    def unary(self):\n",
        "        t=self.peek()\n",
        "        if t in UNARY_OPS:\n",
        "            self.pop(); c=self.unary(); return (\"UN\",t,c)\n",
        "        if t==\"(\":\n",
        "            self.pop(); n=self.expr(0); assert self.pop()==\")\",\"Missing ')'\"\n",
        "            return n\n",
        "        a=self.pop()\n",
        "        return (\"ATOM\", a if a is not None else \"x\")\n",
        "\n",
        "def parse_formula(s):\n",
        "    try: return Parser(lex(s)).expr(0)\n",
        "    except: return (\"ATOM\",\"x\")\n",
        "\n",
        "def atoms_in(node, acc=None):\n",
        "    if acc is None: acc=set()\n",
        "    k=node[0]\n",
        "    if k==\"ATOM\": acc.add(node[1]); return acc\n",
        "    if k==\"UN\": return atoms_in(node[2], acc)\n",
        "    if k==\"BIN\": atoms_in(node[2], acc); atoms_in(node[3], acc); return acc\n",
        "    return acc\n",
        "\n",
        "def depth(node):\n",
        "    k=node[0]\n",
        "    if k==\"ATOM\": return 1\n",
        "    if k==\"UN\": return 1+depth(node[2])\n",
        "    if k==\"BIN\": return 1+max(depth(node[2]), depth(node[3]))\n",
        "    return 1\n",
        "\n",
        "def _u64_from_str(s: str) -> int:\n",
        "    h = hashlib.blake2b(s.encode('utf-8'), digest_size=8).digest()\n",
        "    return int.from_bytes(h, 'big')\n",
        "\n",
        "def bernoulli_from_name(atom: str, probe_idx: int, p: float, seed: int) -> bool:\n",
        "    u = (_u64_from_str(f\"{atom}|{probe_idx}|{seed}\") % (1<<53)) / float(1<<53)\n",
        "    return u < p\n",
        "\n",
        "class ProbeEnv:\n",
        "    def __init__(self, base_env: dict, probe_idx: int, bias_p: float, seed: int):\n",
        "        self.base = base_env; self.m = probe_idx; self.p = float(bias_p); self.seed = int(seed)\n",
        "        self.cache = {}\n",
        "    def get(self, atom: str) -> bool:\n",
        "        if atom in self.base: return bool(self.base[atom])\n",
        "        if atom in self.cache: return self.cache[atom]\n",
        "        v = bernoulli_from_name(atom, self.m, self.p, self.seed)\n",
        "        self.cache[atom] = v\n",
        "        return v\n",
        "\n",
        "def eval_ast(node, env_obj):\n",
        "    k=node[0]\n",
        "    if k==\"ATOM\": return bool(env_obj.get(node[1]))\n",
        "    if k==\"UN\":\n",
        "        _,op,c = node\n",
        "        v = eval_ast(c, env_obj)\n",
        "        return (not v)\n",
        "    if k==\"BIN\":\n",
        "        _,op,l,r = node\n",
        "        a = eval_ast(l, env_obj); b = eval_ast(r, env_obj)\n",
        "        if op==\"AND\": return a and b\n",
        "        if op==\"OR\":  return a or b\n",
        "        if op in (\"IMP\",\"SUB\"): return (not a) or b\n",
        "        if op==\"IFF\": return a==b\n",
        "    return False\n",
        "\n",
        "def op_counts(toks):\n",
        "    return toks.count(\"AND\"), toks.count(\"OR\"), toks.count(\"NOT\"), toks.count(\"IMP\")+toks.count(\"SUB\"), toks.count(\"IFF\")\n",
        "\n",
        "def build_semantic_FP(formulas, M_probes=M_PROBES, seed=SEED):\n",
        "    N = len(formulas)\n",
        "    asts = [parse_formula(s) for s in formulas]\n",
        "    all_atoms = sorted(set().union(*[atoms_in(t) for t in asts]))\n",
        "    A = len(all_atoms)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    biases = np.concatenate([np.full(M_probes//2,0.3), np.full(M_probes - M_probes//2,0.7)])\n",
        "    assignments = []\n",
        "    for p in biases:\n",
        "        vals = rng.random(A) < p\n",
        "        env = {a: bool(v) for a,v in zip(all_atoms, vals)}\n",
        "        assignments.append(env)\n",
        "    T_mat = np.zeros((N, M_probes), dtype=np.float32)\n",
        "    for i,ast in enumerate(asts):\n",
        "        for m_i,base_env in enumerate(assignments):\n",
        "            env_obj = ProbeEnv(base_env, probe_idx=m_i, bias_p=biases[m_i], seed=seed)\n",
        "            T_mat[i,m_i] = 1.0 if eval_ast(ast, env_obj) else 0.0\n",
        "    struct_rows=[]\n",
        "    for s,ast in zip(formulas,asts):\n",
        "        toks = lex(s)\n",
        "        ac = len(atoms_in(ast,set()))\n",
        "        d  = depth(ast)\n",
        "        c_and, c_or, c_not, c_imp, c_iff = op_counts(toks)\n",
        "        struct_rows.append([ac,d,c_and,c_or,c_not,c_imp,c_iff,len(toks)])\n",
        "    STRUCT = np.array(struct_rows,dtype=np.float32)\n",
        "    FP = np.concatenate([T_mat, STRUCT], axis=1).astype(np.float32)\n",
        "    return FP\n",
        "\n",
        "# ---------------------- Model ----------------------\n",
        "class APPNPEncoder(nn.Module):\n",
        "    def __init__(self, d_in, d_hidden, d_out, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(d_in,d_hidden)\n",
        "        self.lin2 = nn.Linear(d_hidden,d_out)\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "    def forward(self,X,A_hat,K=APPNP_K,alpha=APPNP_ALPHA):\n",
        "        H0 = F.relu(self.lin1(X)); H0=self.drop(H0)\n",
        "        H0 = self.lin2(H0)\n",
        "        H = H0\n",
        "        for _ in range(K):\n",
        "            H = (1-alpha)*torch.sparse.mm(A_hat,H)+alpha*H0\n",
        "        return H\n",
        "\n",
        "class JointModel(nn.Module):\n",
        "    def __init__(self,d_in,d_hidden,d_emb):\n",
        "        super().__init__()\n",
        "        self.enc = APPNPEncoder(d_in,d_hidden,d_emb)\n",
        "        self.scale = nn.Parameter(torch.tensor(1.0))\n",
        "        self.bias  = nn.Parameter(torch.tensor(0.0))\n",
        "    def forward_embeddings(self,X,A_hat):\n",
        "        H0 = self.enc(X,A_hat)\n",
        "        norms = H0.norm(dim=1, keepdim=True).clamp_min(1e-6)\n",
        "        Z = H0 / norms.clamp_max(2.0)\n",
        "        return F.normalize(Z, dim=1)\n",
        "    def decode_pairs(self,Z,pairs_idx):\n",
        "        i = torch.as_tensor(pairs_idx[:,0],dtype=torch.long,device=Z.device)\n",
        "        j = torch.as_tensor(pairs_idx[:,1],dtype=torch.long,device=Z.device)\n",
        "        dp = (Z[i]*Z[j]).sum(1)\n",
        "        return torch.sigmoid(self.scale*dp+self.bias)\n",
        "\n",
        "# ---------------------- Metrics ----------------------\n",
        "# ---------------------- Metrics ----------------------\n",
        "def evaluate_pairs(truth, pred, clip_r2_for_display=True):\n",
        "    \"\"\"\n",
        "    Returns dictionary of metrics. R2 is computed exactly.\n",
        "    Optionally returns a capped version for display without altering actual R2.\n",
        "    \"\"\"\n",
        "    mse = float(mean_squared_error(truth, pred))\n",
        "    mae = float(mean_absolute_error(truth, pred))\n",
        "    try:\n",
        "        r2_exact = float(r2_score(truth, pred))  # true R2\n",
        "        r2_display = r2_exact\n",
        "        if clip_r2_for_display and r2_display < -10:\n",
        "            r2_display = -10.0  # only for readability\n",
        "    except:\n",
        "        r2_exact = r2_display = float('nan')\n",
        "    if len(truth) > 1:\n",
        "        pe = float(pearsonr(truth, pred)[0])\n",
        "        sp = float(spearmanr(truth, pred)[0])\n",
        "    else:\n",
        "        pe = sp = float('nan')\n",
        "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2_exact, \"r2_display\": r2_display,\n",
        "            \"pearson\": pe, \"spearman\": sp}\n",
        "\n",
        "def print_metrics(name, m, display_r2=True):\n",
        "    r2_val = m['r2']\n",
        "    print(f\"[{name}] MSE={m['mse']:.6f} MAE={m['mae']:.6f} \"\n",
        "          f\"R2={r2_val:.3f} Pearson={m['pearson']:.3f} Spearman={m['spearman']:.3f}\")\n",
        "\n",
        "\n",
        "# ---------------------- Training ----------------------\n",
        "def train_edges_only(FP_in, train_edge_pairs, train_edge_vals, holdout_edge_pairs, holdout_edge_vals,\n",
        "                     d_hidden=256, d_emb=EMBED_DIM, epochs=EPOCHS, batch_edges_size=BATCH_EDGES_SIZE, lr=LR,\n",
        "                     edge_loss_w=EDGE_LOSS_W):\n",
        "\n",
        "    N, d_in = FP_in.shape\n",
        "    X = torch.tensor(FP_in, dtype=torch.float32, device=DEVICE)\n",
        "    model = JointModel(d_in, d_hidden, d_emb).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    # Build normalized adjacency\n",
        "    A_hat = build_A_hat_from_obs(N, train_edge_pairs, train_edge_vals, edge_temp=EDGE_TEMP, device=DEVICE)\n",
        "    M = len(train_edge_pairs)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        Z = model.forward_embeddings(X, A_hat)\n",
        "\n",
        "        # Edge batch\n",
        "        if M > 0:\n",
        "            sample_size = min(batch_edges_size, M)\n",
        "            idxs = np.random.randint(0, M, size=sample_size)\n",
        "            batch_edge_pairs = train_edge_pairs[idxs]\n",
        "            batch_edge_vals = train_edge_vals[idxs].astype(np.float32)\n",
        "            batch_edge_vals_t = torch.tensor(batch_edge_vals, dtype=torch.float32, device=DEVICE)\n",
        "            pred_batch = model.decode_pairs(Z, batch_edge_pairs).clamp(0,1)\n",
        "            loss_edge = mse_loss(pred_batch, batch_edge_vals_t)\n",
        "        else:\n",
        "            loss_edge = torch.tensor(0.0, device=DEVICE)\n",
        "\n",
        "        # Backprop\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss_edge.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
        "        opt.step()\n",
        "\n",
        "        if ep in {1,2,3,5,10,20,50,100,epochs}:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if len(holdout_edge_pairs) > 0:\n",
        "                    i = torch.as_tensor(holdout_edge_pairs[:,0], dtype=torch.long, device=DEVICE)\n",
        "                    j = torch.as_tensor(holdout_edge_pairs[:,1], dtype=torch.long, device=DEVICE)\n",
        "                    ph = torch.sigmoid(model.scale*(Z[i]*Z[j]).sum(1)+model.bias).clamp(0,1).cpu().numpy()\n",
        "                    metrics = evaluate_pairs(holdout_edge_vals, ph)\n",
        "                    print(f\"[Epoch {ep}] train_edge_loss={float(loss_edge):.6f}\")\n",
        "                    print_metrics(\"Holdout edges\", metrics)\n",
        "\n",
        "    # Final embeddings\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        Z_final = model.forward_embeddings(X, A_hat).cpu().numpy()\n",
        "    return model, Z_final\n",
        "\n",
        "# ---------------------- Pipeline ----------------------\n",
        "def run_edges_pipeline():\n",
        "    # 1) Load CSV\n",
        "    sim_full, formulas_full = load_sim_and_labels(CSV_PATH)\n",
        "    print(\"Loaded sim shape\", sim_full.shape)\n",
        "\n",
        "    # 2) Sample subset\n",
        "    sim, formulas, picked_idx = sample_subset(sim_full, formulas_full, SUBSET_SIZE, SEED)\n",
        "    N = sim.shape[0]\n",
        "    print(\"Using N =\", N, \"formulas (subset).\")\n",
        "\n",
        "    # 3) Observed edges & unobserved\n",
        "    obs_pairs_all, obs_vals_all, unobs_pairs = build_obs_pairs_from_sim(sim, OBS_MISSING_FRAC, SEED)\n",
        "    print(\"Observed edges:\", len(obs_pairs_all), \"Unobserved pairs:\", len(unobs_pairs))\n",
        "\n",
        "    # 4) Split train vs holdout\n",
        "    train_pairs, train_vals, hold_pairs, hold_vals = split_holdout(obs_pairs_all, obs_vals_all, HOLDOUT_EDGE_FRAC, SEED)\n",
        "    print(\"Train observed pairs:\", len(train_pairs), \"Holdout pairs:\", len(hold_pairs))\n",
        "\n",
        "    # 5) Semantic fingerprints\n",
        "    FP = build_semantic_FP(formulas, M_probes=M_PROBES, seed=SEED)\n",
        "    print(\"FP shape:\", FP.shape)\n",
        "\n",
        "    # 6) Train model\n",
        "    model, Z = train_edges_only(FP, train_pairs, train_vals, hold_pairs, hold_vals,\n",
        "                                d_hidden=256, d_emb=EMBED_DIM, epochs=EPOCHS, batch_edges_size=BATCH_EDGES_SIZE, lr=LR)\n",
        "\n",
        "    # 7) Final holdout evaluation\n",
        "    if len(hold_pairs) > 0:\n",
        "        Zt = torch.tensor(Z, dtype=torch.float32, device=DEVICE)\n",
        "        i = torch.as_tensor(hold_pairs[:,0], dtype=torch.long, device=DEVICE)\n",
        "        j = torch.as_tensor(hold_pairs[:,1], dtype=torch.long, device=DEVICE)\n",
        "        with torch.no_grad():\n",
        "            ph = torch.sigmoid(model.scale*(Zt[i]*Zt[j]).sum(1)+model.bias).clamp(0,1).cpu().numpy()\n",
        "        m_final = evaluate_pairs(hold_vals, ph)\n",
        "        print_metrics(\"Final Holdout\", m_final)\n",
        "\n",
        "    # 8) Example unobserved predictions\n",
        "    if len(unobs_pairs) > 0:\n",
        "        sample_unobs = unobs_pairs[:200]\n",
        "        ii = torch.as_tensor(sample_unobs[:,0], dtype=torch.long, device=DEVICE)\n",
        "        jj = torch.as_tensor(sample_unobs[:,1], dtype=torch.long, device=DEVICE)\n",
        "        with torch.no_grad():\n",
        "            ph_unobs = torch.sigmoid(model.scale*(Zt[ii]*Zt[jj]).sum(1)+model.bias).clamp(0,1).cpu().numpy()\n",
        "        print(\"Example predicted unobserved (first 20):\", ph_unobs[:20])\n",
        "\n",
        "    # 9) Save embeddings\n",
        "    np.savez(OUT_ARTIFACT, Z=Z, picked_idx=picked_idx)\n",
        "    print(\"Saved artifacts to\", OUT_ARTIFACT)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    run_edges_pipeline()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-RTs1tUmlG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeKlKVBgBSZJ",
        "outputId": "b2c298a8-9f9b-4d19-a1ee-c7ad2f746edd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xBQb0xaG_1gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6HzNxE4E_JwD"
      }
    }
  ]
}